{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3bcfb52",
   "metadata": {},
   "source": [
    "Data Preparation: Missing values, feature engineering, encoding, train-test split.\n",
    "Model Building: Linear Regression, Random Forest, XGBoost for both Regression (Claim Severity) and Classification (Claim Probability).\n",
    "Model Evaluation: RMSE, R-squared for regression; Accuracy, Precision, Recall, F1-score for classification.\n",
    "Model Interpretability: SHAP/LIME.\n",
    "Modular Code: Putting models and helper functions into models.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb806f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully.\n",
      "\n",
      "--- DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000098 entries, 0 to 1000097\n",
      "Data columns (total 53 columns):\n",
      " #   Column                       Non-Null Count    Dtype         \n",
      "---  ------                       --------------    -----         \n",
      " 0   underwritten_cover_id        1000098 non-null  int64         \n",
      " 1   policy_id                    1000098 non-null  int64         \n",
      " 2   transaction_month            1000098 non-null  datetime64[ns]\n",
      " 3   is_vat_registered            1000098 non-null  bool          \n",
      " 4   citizenship                  1000098 non-null  object        \n",
      " 5   legaltype                    1000098 non-null  object        \n",
      " 6   title                        1000098 non-null  object        \n",
      " 7   language                     1000098 non-null  object        \n",
      " 8   bank                         854137 non-null   object        \n",
      " 9   account_type                 959866 non-null   object        \n",
      " 10  marital_status               1000098 non-null  object        \n",
      " 11  gender                       1000098 non-null  object        \n",
      " 12  country                      1000098 non-null  object        \n",
      " 13  province                     1000098 non-null  object        \n",
      " 14  postal_code                  1000098 non-null  int64         \n",
      " 15  main_crestazone              1000098 non-null  object        \n",
      " 16  sub_crestazone               1000098 non-null  object        \n",
      " 17  itemtype                     1000098 non-null  object        \n",
      " 18  mm_code                      999546 non-null   float64       \n",
      " 19  vehicle_type                 1000098 non-null  object        \n",
      " 20  registration_year            1000098 non-null  int64         \n",
      " 21  make                         1000098 non-null  object        \n",
      " 22  model                        1000098 non-null  object        \n",
      " 23  cylinders                    999546 non-null   float64       \n",
      " 24  cubic_capacity               1000098 non-null  float64       \n",
      " 25  kilowatts                    1000098 non-null  float64       \n",
      " 26  body_type                    1000098 non-null  object        \n",
      " 27  number_of_doors              999546 non-null   float64       \n",
      " 28  vehicle_intro_date           999546 non-null   object        \n",
      " 29  custom_value_estimate        1000098 non-null  float64       \n",
      " 30  alarm_immobiliser            1000098 non-null  object        \n",
      " 31  tracking_device              1000098 non-null  object        \n",
      " 32  capital_outstanding          1000098 non-null  float64       \n",
      " 33  new_vehicle                  846803 non-null   object        \n",
      " 34  written_off                  358197 non-null   object        \n",
      " 35  rebuilt_vehicle              358197 non-null   object        \n",
      " 36  converted_vehicle            358197 non-null   object        \n",
      " 37  cross_border                 698 non-null      object        \n",
      " 38  number_of_vehicles_in_fleet  0 non-null        float64       \n",
      " 39  sum_insured                  1000098 non-null  float64       \n",
      " 40  term_frequency               0 non-null        float64       \n",
      " 41  calculated_premium_per_term  1000098 non-null  float64       \n",
      " 42  excess_selected              1000098 non-null  object        \n",
      " 43  cover_category               1000098 non-null  object        \n",
      " 44  cover_type                   1000098 non-null  object        \n",
      " 45  cover_group                  1000098 non-null  object        \n",
      " 46  section                      1000098 non-null  object        \n",
      " 47  product                      1000098 non-null  object        \n",
      " 48  statutory_class              1000098 non-null  object        \n",
      " 49  statutory_risk_type          1000098 non-null  object        \n",
      " 50  total_premium                1000098 non-null  float64       \n",
      " 51  total_claims                 1000098 non-null  float64       \n",
      " 52  loss_ratio                   1000098 non-null  float64       \n",
      "dtypes: bool(1), datetime64[ns](1), float64(14), int64(4), object(33)\n",
      "memory usage: 397.7+ MB\n",
      "\n",
      "--- Missing Values ---\n",
      "underwritten_cover_id                0\n",
      "policy_id                            0\n",
      "transaction_month                    0\n",
      "is_vat_registered                    0\n",
      "citizenship                          0\n",
      "legaltype                            0\n",
      "title                                0\n",
      "language                             0\n",
      "bank                            145961\n",
      "account_type                     40232\n",
      "marital_status                       0\n",
      "gender                               0\n",
      "country                              0\n",
      "province                             0\n",
      "postal_code                          0\n",
      "main_crestazone                      0\n",
      "sub_crestazone                       0\n",
      "itemtype                             0\n",
      "mm_code                            552\n",
      "vehicle_type                         0\n",
      "registration_year                    0\n",
      "make                                 0\n",
      "model                                0\n",
      "cylinders                          552\n",
      "cubic_capacity                       0\n",
      "kilowatts                            0\n",
      "body_type                            0\n",
      "number_of_doors                    552\n",
      "vehicle_intro_date                 552\n",
      "custom_value_estimate                0\n",
      "alarm_immobiliser                    0\n",
      "tracking_device                      0\n",
      "capital_outstanding                  0\n",
      "new_vehicle                     153295\n",
      "written_off                     641901\n",
      "rebuilt_vehicle                 641901\n",
      "converted_vehicle               641901\n",
      "cross_border                    999400\n",
      "number_of_vehicles_in_fleet    1000098\n",
      "sum_insured                          0\n",
      "term_frequency                 1000098\n",
      "calculated_premium_per_term          0\n",
      "excess_selected                      0\n",
      "cover_category                       0\n",
      "cover_type                           0\n",
      "cover_group                          0\n",
      "section                              0\n",
      "product                              0\n",
      "statutory_class                      0\n",
      "statutory_risk_type                  0\n",
      "total_premium                        0\n",
      "total_claims                         0\n",
      "loss_ratio                           0\n",
      "dtype: int64\n",
      "\n",
      "--- Value Counts for Key Categorical Candidates ---\n",
      "Warning: Column 'PolicyType' not found in DataFrame.\n",
      "Warning: Column 'VehicleUse' not found in DataFrame.\n",
      "Warning: Column 'CoverageType' not found in DataFrame.\n",
      "Warning: Column 'Province' not found in DataFrame.\n",
      "Warning: Column 'Gender' not found in DataFrame.\n",
      "\n",
      "Initial data loading and inspection complete. Proceed to next cells.\n"
     ]
    }
   ],
   "source": [
    "# notebooks/03_model_development.ipynb\n",
    "\n",
    "\n",
    "# 1. Setup and Data Loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import shap\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize df to None outside the try block\n",
    "df = None\n",
    "\n",
    "# Load the processed data\n",
    "# Assuming cleaned_data.parquet is saved in the 'Data/processed/' directory\n",
    "try:\n",
    "    # --- CHANGE THIS LINE ---\n",
    "    df = pd.read_parquet('../Data/processed/cleaned_data.parquet') # <--- CHANGE THIS FILENAME\n",
    "    # --- TO THIS ONE ---\n",
    "    print(\"DataFrame loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'Data/processed/cleaned_data.parquet' not found.\")\n",
    "    print(\"Please ensure the processed data from Task 2/3 is saved in 'Data/processed/cleaned_data.parquet'.\")\n",
    "    print(\"Exiting as core data is missing.\")\n",
    "    raise FileNotFoundError(\"Processed DataFrame 'cleaned_data.parquet' not found at the specified path.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading the DataFrame: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- ONLY PROCEED IF DF IS LOADED ---\n",
    "if df is not None:\n",
    "    # Display basic info\n",
    "    print(\"\\n--- DataFrame Info ---\")\n",
    "    df.info()\n",
    "\n",
    "    print(\"\\n--- Missing Values ---\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    print(\"\\n--- Value Counts for Key Categorical Candidates ---\")\n",
    "    # Identify potential categorical columns. Based on typical insurance data, and assuming some initial processing.\n",
    "    # 'PolicyID', 'ClaimID', 'TotalClaims' (regression target) should not be treated as categorical features.\n",
    "    # We will derive 'HasClaim' as a new binary column.\n",
    "    categorical_cols_initial_check = ['PolicyType', 'VehicleUse', 'CoverageType', 'Province', 'Gender']\n",
    "\n",
    "    for col in categorical_cols_initial_check:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\nValue Counts for {col}:\")\n",
    "            print(df[col].value_counts())\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in DataFrame.\")\n",
    "\n",
    "    # Check numerical features that might be discrete or low-cardinality and could be treated as categorical\n",
    "    numerical_categorical_candidates = ['VehicleYear']\n",
    "    for col in numerical_categorical_candidates:\n",
    "        if col in df.columns and df[col].nunique() < 20:\n",
    "            print(f\"\\nUnique values for numerical candidate {col}:\")\n",
    "            print(df[col].value_counts().sort_index())\n",
    "    print(\"\\nInitial data loading and inspection complete. Proceed to next cells.\")\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame 'df' was not loaded. Subsequent operations will fail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e7e8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Columns after Feature Engineering and Missing Value Handling ---\n",
      "Total Features: 48\n",
      "Numerical Features identified: 18 ['is_vat_registered', 'mm_code', 'registration_year', 'cylinders', 'cubic_capacity', 'kilowatts', 'number_of_doors', 'custom_value_estimate', 'capital_outstanding', 'sum_insured', 'total_premium', 'month', 'year', 'day_of_week', 'vehicle_age_at_transaction', 'exposure_x_kilowatts', 'claims_per_kilowatt', 'vehicle_intro_year']\n",
      "Categorical Features identified: 23 ['citizenship', 'legaltype', 'title', 'language', 'bank', 'account_type', 'marital_status', 'gender', 'country', 'province', 'main_crestazone', 'sub_crestazone', 'itemtype', 'vehicle_type', 'body_type', 'excess_selected', 'cover_category', 'cover_type', 'cover_group', 'section', 'product', 'statutory_class', 'statutory_risk_type']\n",
      "\n",
      "Severity Model - Training Data Shape: (2230, 48), Test Data Shape: (558, 48)\n",
      "Probability Model - Training Data Shape: (800078, 48), Test Data Shape: (200020, 48)\n",
      "Probability Model - Train Claim Ratio: 0.0028\n",
      "Probability Model - Test Claim Ratio: 0.0028\n"
     ]
    }
   ],
   "source": [
    "# 03_model_development.ipynb (Cont.)\n",
    "\n",
    "# 2. Data Preparation\n",
    "\n",
    "# Define the two modeling datasets\n",
    "# Target variable for probability model: 1 if claim, 0 if no claim\n",
    "# Create this new column 'has_claim'\n",
    "df['has_claim'] = df['total_claims'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Dataset for Claim Severity Prediction (Regression): Policies with claims\n",
    "df_severity = df[df['has_claim'] == 1].copy()\n",
    "# Target variable for severity model\n",
    "y_severity = df_severity['total_claims']\n",
    "\n",
    "\n",
    "# Feature Engineering (Apply to df, then create X_severity and X_probability)\n",
    "def feature_engineer(dataframe):\n",
    "    df_fe = dataframe.copy()\n",
    "\n",
    "    # --- Date Features ---\n",
    "    # Convert 'transaction_month' to datetime if not already (info says datetime64[ns], but good to be explicit)\n",
    "    df_fe['transaction_month'] = pd.to_datetime(df_fe['transaction_month'])\n",
    "    df_fe['month'] = df_fe['transaction_month'].dt.month\n",
    "    df_fe['year'] = df_fe['transaction_month'].dt.year\n",
    "    df_fe['day_of_week'] = df_fe['transaction_month'].dt.dayofweek # Monday=0, Sunday=6\n",
    "\n",
    "    # Vehicle Age at transaction (assuming 'registration_year' is vehicle's manufacturing/registration year)\n",
    "    # Be careful with 'registration_year' vs. 'vehicle_intro_date'\n",
    "    # Let's use 'registration_year' as 'vehicle_intro_date' has missing values and is object dtype.\n",
    "    df_fe['vehicle_age_at_transaction'] = df_fe['year'] - df_fe['registration_year']\n",
    "    # Handle potential negative or zero ages for new vehicles if registration year is same as transaction year\n",
    "    df_fe['vehicle_age_at_transaction'] = df_fe['vehicle_age_at_transaction'].apply(lambda x: max(0, x))\n",
    "\n",
    "\n",
    "    # Interaction features\n",
    "    df_fe['exposure_x_kilowatts'] = df_fe['total_premium'] / df_fe['calculated_premium_per_term'] * df_fe['kilowatts'] # Approximation of Exposure\n",
    "    df_fe['claims_per_kilowatt'] = df_fe['total_claims'] / (df_fe['kilowatts'] + 1e-6) # Add small constant to avoid div by zero\n",
    "\n",
    "    # Binning for a continuous variable if desired (e.g., cubic_capacity)\n",
    "    # For now, keeping as continuous, but remember this option for further refinement.\n",
    "\n",
    "\n",
    "    # Handle specific 'object' columns that might be boolean-like or numeric that were ingested as object\n",
    "    # If `new_vehicle`, `written_off`, etc., are strings like 'Yes'/'No', convert to 1/0\n",
    "    for col_bool in ['new_vehicle', 'written_off', 'rebuilt_vehicle', 'converted_vehicle', 'alarm_immobiliser', 'tracking_device', 'cross_border', 'is_vat_registered']:\n",
    "        if col_bool in df_fe.columns:\n",
    "            # First, fill NaN or a placeholder, then map\n",
    "            # Assuming 'Yes'/'True' maps to 1, others to 0 or specific handling for NaN\n",
    "            df_fe[col_bool] = df_fe[col_bool].map({'Yes': 1, 'No': 0, True: 1, False: 0}).fillna(-1).astype(int) # -1 for missing or unknown\n",
    "\n",
    "    return df_fe\n",
    "\n",
    "df_fe = feature_engineer(df)\n",
    "\n",
    "# --- Missing Data Handling ---\n",
    "# Columns with 100% missing values should be dropped\n",
    "cols_to_drop_due_to_missing = ['number_of_vehicles_in_fleet', 'term_frequency']\n",
    "df_fe = df_fe.drop(columns=cols_to_drop_due_to_missing, errors='ignore')\n",
    "\n",
    "# Impute 'bank', 'account_type', 'new_vehicle' (if not handled by mapping above) with a placeholder 'Missing'\n",
    "for col in ['bank', 'account_type']: # 'new_vehicle' should be handled by mapping now\n",
    "    if col in df_fe.columns:\n",
    "        df_fe[col] = df_fe[col].fillna('Missing')\n",
    "\n",
    "# Impute numerical columns with low missing values (mm_code, cylinders, number_of_doors, vehicle_intro_date)\n",
    "# For 'vehicle_intro_date', convert to numeric (e.g., year) if possible, or drop if too complex for simple imputation.\n",
    "# Given it's an object, let's just drop it for now for simplicity, or convert it to a meaningful numerical feature like 'intro_year'.\n",
    "# If 'vehicle_intro_date' is like 'YYYY-MM-DD', we can extract year and fill NaNs.\n",
    "if 'vehicle_intro_date' in df_fe.columns:\n",
    "    # Try converting to datetime and extracting year, then impute\n",
    "    df_fe['vehicle_intro_year'] = pd.to_datetime(df_fe['vehicle_intro_date'], errors='coerce').dt.year\n",
    "    df_fe['vehicle_intro_year'] = df_fe['vehicle_intro_year'].fillna(df_fe['vehicle_intro_year'].median()) # Impute with median year\n",
    "    df_fe = df_fe.drop(columns=['vehicle_intro_date'], errors='ignore') # Drop original object column\n",
    "\n",
    "# For other numerical columns, impute with median\n",
    "for col in ['mm_code', 'cylinders', 'number_of_doors']:\n",
    "    if col in df_fe.columns and df_fe[col].isnull().any():\n",
    "        df_fe[col] = df_fe[col].fillna(df_fe[col].median())\n",
    "\n",
    "\n",
    "# Define features for modeling\n",
    "# Drop original target variables, IDs, and columns already handled or with too many unique values for OHE\n",
    "# 'postal_code', 'make', 'model' can have very high cardinality. For now, dropping 'postal_code', 'make', 'model'.\n",
    "# In a real project, 'make'/'model' might need more advanced embedding or grouping.\n",
    "# 'title', 'language', 'country', 'main_crestazone', 'sub_crestazone', 'itemtype', 'product', 'section', 'statutory_class', 'statutory_risk_type'\n",
    "# These are still many categorical features. We might need to reduce the list for simpler models, or expect OHE to create many columns.\n",
    "\n",
    "features_to_drop_overall = [\n",
    "    'underwritten_cover_id', 'policy_id', 'transaction_month',\n",
    "    'total_claims', 'has_claim', # These are targets or derived targets\n",
    "    'calculated_premium_per_term', # This is a conceptual target for optimization, not a feature for severity/probability\n",
    "    'loss_ratio', # Derived from claims and premium, can cause data leakage\n",
    "    'postal_code', 'make', 'model' # High cardinality, dropping for simplicity\n",
    "]\n",
    "\n",
    "# Ensure we're only dropping columns that exist in the DataFrame\n",
    "features_to_drop_overall = [f for f in features_to_drop_overall if f in df_fe.columns]\n",
    "\n",
    "X_all = df_fe.drop(columns=features_to_drop_overall, errors='ignore')\n",
    "\n",
    "# Create X for severity model (only policies with claims)\n",
    "X_severity = X_all[df_fe['has_claim'] == 1].copy()\n",
    "# Ensure y_severity is aligned with X_severity's index\n",
    "y_severity = df_fe.loc[X_severity.index, 'total_claims']\n",
    "\n",
    "\n",
    "# Create X for probability model (all policies)\n",
    "X_probability = X_all.copy()\n",
    "y_probability = df_fe['has_claim']\n",
    "\n",
    "\n",
    "# Identify numerical and categorical columns for preprocessing pipelines AFTER dropping/engineering\n",
    "numerical_cols = X_probability.select_dtypes(include=np.number).columns.tolist()\n",
    "# Filter out boolean columns if they were not converted to int during feature engineering\n",
    "numerical_cols = [col for col in numerical_cols if col not in ['is_vat_registered_bool', 'new_vehicle', 'written_off', 'rebuilt_vehicle', 'converted_vehicle', 'alarm_immobiliser', 'tracking_device', 'cross_border'] ] # Assuming these are mapped to int now\n",
    "\n",
    "categorical_cols = X_probability.select_dtypes(include='object').columns.tolist()\n",
    "# Add the boolean/integer-mapped columns that might still be considered categorical by the model if they are 0/1/-1\n",
    "# (e.g., for tree-based models, they work fine as numbers, but for linear models, they might need OHE depending on how we treat -1)\n",
    "# For simplicity, let's keep boolean mapped values as numerical for now and let the scaler handle them.\n",
    "\n",
    "# Final check for numerical/categorical lists\n",
    "print(\"\\n--- Columns after Feature Engineering and Missing Value Handling ---\")\n",
    "print(\"Total Features:\", len(X_probability.columns))\n",
    "print(\"Numerical Features identified:\", len(numerical_cols), numerical_cols)\n",
    "print(\"Categorical Features identified:\", len(categorical_cols), categorical_cols)\n",
    "\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "# Numerical: Standard Scaling\n",
    "# Categorical: One-Hot Encoding (handle_unknown='ignore' for unseen categories in test set)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough' # Keep other columns if any (e.g. if some columns are bool dtype, they will pass through)\n",
    ")\n",
    "\n",
    "\n",
    "# Train-Test Split for both models\n",
    "# Severity Model (only for policies with claims)\n",
    "X_train_severity, X_test_severity, y_train_severity, y_test_severity = train_test_split(\n",
    "    X_severity, y_severity, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"\\nSeverity Model - Training Data Shape: {X_train_severity.shape}, Test Data Shape: {X_test_severity.shape}\")\n",
    "\n",
    "# Probability Model (all policies)\n",
    "X_train_probability, X_test_probability, y_train_probability, y_test_probability = train_test_split(\n",
    "    X_probability, y_probability, test_size=0.2, random_state=42, stratify=y_probability # Stratify for imbalanced classes\n",
    ")\n",
    "print(f\"Probability Model - Training Data Shape: {X_train_probability.shape}, Test Data Shape: {X_test_probability.shape}\")\n",
    "print(f\"Probability Model - Train Claim Ratio: {y_train_probability.mean():.4f}\")\n",
    "print(f\"Probability Model - Test Claim Ratio: {y_test_probability.mean():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
