{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e29718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eep\\AppData\\Local\\Temp\\ipykernel_17412\\1836500419.py:46: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_df = pd.read_csv(raw_data_file_path, sep='|')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns cleaned.\n",
      "Transaction_month converted to datetime.\n",
      "Specific 'Not specified' values handled.\n",
      "Loss Ratio calculated.\n",
      "Key numerical columns converted to numeric.\n",
      "Filled NaN in custom_value_estimate with median: 220000.0\n",
      "Filled NaN in capital_outstanding with median: 0.0\n",
      "Filled NaN in kilowatts with median: 111.0\n",
      "Filled NaN in cubic_capacity with median: 2694.0\n",
      "Filled NaN in gender with 'Unknown'.\n",
      "Filled NaN in marital_status with 'Unknown'.\n",
      "Filled NaN in vehicle_type with 'Unknown'.\n",
      "Filled NaN in body_type with 'Unknown'.\n",
      "Filled NaN in make with 'Unknown'.\n",
      "Filled NaN in model with 'Unknown'.\n",
      "Data loaded and preprocessed successfully for Task 3.\n",
      "Shape of df_processed: (1000098, 53)\n",
      "\n",
      "Derived metrics added:\n",
      "Claim Frequency (policies with claims): 0.0028\n",
      "Overall Claim Severity (average claim amount for claims): 23273.39\n",
      "Overall Average Margin: -2.96\n",
      "\n",
      "--- Hypothesis 1: Risk differences across provinces ---\n",
      "\n",
      "Claim Frequency by Province:\n",
      "has_claim           0     1\n",
      "province                   \n",
      "Eastern Cape    30286    50\n",
      "Free State       8088    11\n",
      "Gauteng        392543  1322\n",
      "KwaZulu-Natal  169298   483\n",
      "Limpopo         24769    67\n",
      "Mpumalanga      52590   128\n",
      "North West     142938   349\n",
      "Northern Cape    6372     8\n",
      "Western Cape   170426   370\n",
      "\n",
      "Chi-squared test for Claim Frequency (Province):\n",
      "Chi2 Stat: 104.19, P-value: 0.0000\n",
      "Decision: Reject the Null Hypothesis (H₀).\n",
      "Interpretation: There is a statistically significant difference in claim frequency across provinces.\n",
      "\n",
      "Claim Frequency by Province (proportion of policies with claims):\n",
      "province\n",
      "Gauteng          0.003356\n",
      "KwaZulu-Natal    0.002845\n",
      "Limpopo          0.002698\n",
      "North West       0.002436\n",
      "Mpumalanga       0.002428\n",
      "Western Cape     0.002166\n",
      "Eastern Cape     0.001648\n",
      "Free State       0.001358\n",
      "Northern Cape    0.001254\n",
      "Name: has_claim, dtype: float64\n",
      "Business Recommendation: Provinces like Gauteng exhibit higher claim frequencies compared to Northern Cape and others. This suggests that regional adjustments to premiums based on the likelihood of a claim might be warranted.\n",
      "\n",
      "Claim Severity by Province:\n",
      "ANOVA test for Claim Severity (Province):\n",
      "F-statistic: 4.83, P-value: 0.0000\n",
      "Decision: Reject the Null Hypothesis (H₀).\n",
      "Interpretation: There is a statistically significant difference in claim severity across provinces.\n",
      "\n",
      "Claim Severity by Province (average claim amount for policies with claims):\n",
      "province\n",
      "Free State       32265.661085\n",
      "KwaZulu-Natal    29609.487473\n",
      "Western Cape     28095.849881\n",
      "Eastern Cape     27128.533277\n",
      "Gauteng          22243.878396\n",
      "North West       16963.467035\n",
      "Mpumalanga       15979.553421\n",
      "Limpopo          15171.294187\n",
      "Northern Cape    11186.313596\n",
      "Name: total_claims, dtype: float64\n",
      "Business Recommendation: Provinces like Free State show higher average claim amounts when a claim occurs, compared to Northern Cape. This indicates a need to consider regional factors when setting cover limits or excess options to manage potential payout costs.\n"
     ]
    }
   ],
   "source": [
    "# notebooks/02_hypothesis_testing.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, f_oneway, ttest_ind\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the current working directory (where the notebook is launched from)\n",
    "current_working_directory = os.getcwd()\n",
    "\n",
    "# Assuming 'src' is one level up from the 'notebooks' directory\n",
    "# So, if CWD is 'project_root/notebooks', then project_root is os.path.dirname(CWD)\n",
    "project_root = os.path.dirname(current_working_directory)\n",
    "\n",
    "# Construct the path to the 'src' directory\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "\n",
    "# Add the 'src' directory to the system path if it's not already there\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    print(f\"Added '{src_path}' to sys.path.\")\n",
    "\n",
    "# --- Optional: Add checks for debugging (keep these, they are helpful) ---\n",
    "if not os.path.exists(src_path):\n",
    "    print(f\"ERROR: The 'src' directory does not exist at '{src_path}'. Please check your project structure.\")\n",
    "elif not os.path.isdir(src_path):\n",
    "    print(f\"ERROR: '{src_path}' is not a directory.\")\n",
    "elif not os.path.exists(os.path.join(src_path, 'data_tools.py')):\n",
    "    print(f\"ERROR: 'data_tools.py' not found in '{src_path}'. Please ensure the file exists and is named 'data_tools.py'.\")\n",
    "# --- End Optional Checks ---\n",
    "\n",
    "# CORRECTED IMPORTS: Import the correct functions from data_tools and constants from utils\n",
    "from data_tools import preprocess_data\n",
    "from utils import RAW_DATA_PATH # Import RAW_DATA_PATH from utils\n",
    "\n",
    "# Load the raw data\n",
    "# Use RAW_DATA_PATH from utils, assuming it's correctly configured\n",
    "# The MachineLearningRating_v3.txt file is pipe-separated\n",
    "raw_data_file_path = RAW_DATA_PATH\n",
    "\n",
    "# Read the raw data with the correct separator\n",
    "raw_df = pd.read_csv(raw_data_file_path, sep='|')\n",
    "\n",
    "# Preprocess the raw data using the imported preprocess_data function\n",
    "df_processed = preprocess_data(raw_df)\n",
    "\n",
    "print(\"Data loaded and preprocessed successfully for Task 3.\")\n",
    "print(f\"Shape of df_processed: {df_processed.shape}\")\n",
    "\n",
    "# Create 'has_claim' column (for Claim Frequency)\n",
    "# If total_claims is > 0, then a claim occurred (1), else no claim (0)\n",
    "df_processed['has_claim'] = (df_processed['total_claims'] > 0).astype(int)\n",
    "\n",
    "# Create 'margin' column\n",
    "df_processed['margin'] = df_processed['total_premium'] - df_processed['total_claims']\n",
    "\n",
    "# Prepare data for Claim Severity: only policies where a claim occurred\n",
    "df_claims_only = df_processed[df_processed['has_claim'] == 1].copy()\n",
    "\n",
    "print(\"\\nDerived metrics added:\")\n",
    "print(f\"Claim Frequency (policies with claims): {df_processed['has_claim'].mean():.4f}\")\n",
    "print(f\"Overall Claim Severity (average claim amount for claims): {df_claims_only['total_claims'].mean():.2f}\")\n",
    "print(f\"Overall Average Margin: {df_processed['margin'].mean():.2f}\")\n",
    "\n",
    "\n",
    "# --- Hypothesis 1: Risk differences across provinces ---\n",
    "print(\"\\n--- Hypothesis 1: Risk differences across provinces ---\")\n",
    "\n",
    "# --- Claim Frequency by Province (Chi-squared Test) ---\n",
    "print(\"\\nClaim Frequency by Province:\")\n",
    "contingency_table_province_freq = pd.crosstab(df_processed['province'], df_processed['has_claim'])\n",
    "print(contingency_table_province_freq)\n",
    "\n",
    "# Ensure enough data for Chi-squared test (at least 2x2 table and not all zero counts)\n",
    "if contingency_table_province_freq.shape[0] > 1 and contingency_table_province_freq.shape[1] > 1 and contingency_table_province_freq.min().min() > 0:\n",
    "    chi2_freq, p_value_freq, _, _ = chi2_contingency(contingency_table_province_freq)\n",
    "    print(f\"\\nChi-squared test for Claim Frequency (Province):\")\n",
    "    print(f\"Chi2 Stat: {chi2_freq:.2f}, P-value: {p_value_freq:.4f}\")\n",
    "\n",
    "    if p_value_freq < 0.05:\n",
    "        print(\"Decision: Reject the Null Hypothesis (H₀).\")\n",
    "        print(\"Interpretation: There is a statistically significant difference in claim frequency across provinces.\")\n",
    "        # Business Recommendation for frequency\n",
    "        province_freq = df_processed.groupby('province')['has_claim'].mean().sort_values(ascending=False)\n",
    "        print(\"\\nClaim Frequency by Province (proportion of policies with claims):\")\n",
    "        print(province_freq)\n",
    "        print(f\"Business Recommendation: Provinces like {province_freq.index[0]} exhibit higher claim frequencies compared to {province_freq.index[-1]} and others. This suggests that regional adjustments to premiums based on the likelihood of a claim might be warranted.\")\n",
    "    else:\n",
    "        print(\"Decision: Fail to Reject the Null Hypothesis (H₀).\")\n",
    "        print(\"Interpretation: There is no statistically significant difference in claim frequency across provinces.\")\n",
    "else:\n",
    "    print(\"Not enough unique provinces or sufficient data for Chi-squared test on Claim Frequency.\")\n",
    "\n",
    "\n",
    "# --- Claim Severity by Province (ANOVA Test) ---\n",
    "print(\"\\nClaim Severity by Province:\")\n",
    "# Filter for claims only for severity analysis\n",
    "province_groups_severity = [df_claims_only['total_claims'][df_claims_only['province'] == p] for p in df_claims_only['province'].unique()]\n",
    "\n",
    "# Filter out empty groups or groups with only one observation for ANOVA\n",
    "province_groups_severity = [group for group in province_groups_severity if len(group) > 1]\n",
    "\n",
    "if len(province_groups_severity) > 1: # Ensure there's more than one group to compare\n",
    "    f_stat_severity, p_value_severity = f_oneway(*province_groups_severity)\n",
    "    print(f\"ANOVA test for Claim Severity (Province):\")\n",
    "    print(f\"F-statistic: {f_stat_severity:.2f}, P-value: {p_value_severity:.4f}\")\n",
    "\n",
    "    if p_value_severity < 0.05:\n",
    "        print(\"Decision: Reject the Null Hypothesis (H₀).\")\n",
    "        print(\"Interpretation: There is a statistically significant difference in claim severity across provinces.\")\n",
    "        # Business Recommendation for severity\n",
    "        province_severity = df_claims_only.groupby('province')['total_claims'].mean().sort_values(ascending=False)\n",
    "        print(\"\\nClaim Severity by Province (average claim amount for policies with claims):\")\n",
    "        print(province_severity)\n",
    "        print(f\"Business Recommendation: Provinces like {province_severity.index[0]} show higher average claim amounts when a claim occurs, compared to {province_severity.index[-1]}. This indicates a need to consider regional factors when setting cover limits or excess options to manage potential payout costs.\")\n",
    "    else:\n",
    "        print(\"Decision: Fail to Reject the Null Hypothesis (H₀).\")\n",
    "        print(\"Interpretation: There is no statistically significant difference in claim severity across provinces.\")\n",
    "else:\n",
    "    print(\"Not enough unique provinces with sufficient claims to perform ANOVA for Claim Severity.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992d2bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hypothesis 2: Risk differences between zip codes (postal codes) ---\n",
      "\n",
      "Claim Frequency by Postal Code:\n",
      "Not enough valid postal codes or sufficient data to perform Chi-squared test for Claim Frequency.\n",
      "\n",
      "Claim Severity by Postal Code:\n",
      "\n",
      "ANOVA test for Claim Severity (Postal Code):\n",
      "F-statistic: 1.18, P-value: 0.0271\n",
      "Decision: Reject the Null Hypothesis (H₀).\n",
      "Interpretation: There is a statistically significant difference in claim severity across postal codes.\n",
      "\n",
      "Top 5 Postal Codes by Claim Severity:\n",
      "postal_code\n",
      "4680    260087.719298\n",
      "4820    181480.798246\n",
      "1791    173481.535088\n",
      "1610    163104.473684\n",
      "9756    157520.359649\n",
      "Name: total_claims, dtype: float64\n",
      "\n",
      "Bottom 5 Postal Codes by Claim Severity:\n",
      "postal_code\n",
      "7503    614.035088\n",
      "721     610.198830\n",
      "9306    531.350877\n",
      "6506    490.000000\n",
      "1559    389.956140\n",
      "Name: total_claims, dtype: float64\n",
      "Business Recommendation: Claim severity varies significantly by postal code. Certain areas are associated with higher average claim costs, which could necessitate higher excesses or tailored product offerings in those regions to maintain profitability.\n"
     ]
    }
   ],
   "source": [
    "# --- Hypothesis 2: Risk differences between zip codes (postal codes) ---\n",
    "print(\"\\n--- Hypothesis 2: Risk differences between zip codes (postal codes) ---\")\n",
    "\n",
    "# --- Claim Frequency by Postal Code (Chi-squared Test) ---\n",
    "print(\"\\nClaim Frequency by Postal Code:\")\n",
    "contingency_table_zip_freq = pd.crosstab(df_processed['postal_code'], df_processed['has_claim'])\n",
    "\n",
    "# Filter out postal codes with very few entries if chi-squared gives errors\n",
    "min_observations_for_chi2 = 10 # Adjust as needed\n",
    "valid_zip_codes_freq = contingency_table_zip_freq[contingency_table_zip_freq.sum(axis=1) >= min_observations_for_chi2].index\n",
    "contingency_table_zip_freq_filtered = contingency_table_zip_freq.loc[valid_zip_codes_freq]\n",
    "\n",
    "if not contingency_table_zip_freq_filtered.empty and \\\n",
    "   contingency_table_zip_freq_filtered.shape[0] > 1 and \\\n",
    "   contingency_table_zip_freq_filtered.shape[1] > 1 and \\\n",
    "   contingency_table_zip_freq_filtered.min().min() > 0: # Ensure enough data for test\n",
    "    chi2_zip_freq, p_value_zip_freq, _, _ = chi2_contingency(contingency_table_zip_freq_filtered)\n",
    "    print(f\"\\nChi-squared test for Claim Frequency (Postal Code - filtered for >= {min_observations_for_chi2} policies):\")\n",
    "    print(f\"Chi2 Stat: {chi2_zip_freq:.2f}, P-value: {p_value_zip_freq:.4f}\")\n",
    "\n",
    "    if p_value_zip_freq < 0.05:\n",
    "        print(\"Decision: Reject the Null Hypothesis (H₀).\")\n",
    "        print(\"Interpretation: There is a statistically significant difference in claim frequency across postal codes.\")\n",
    "        # Business Recommendation for frequency\n",
    "        zip_freq = df_processed.groupby('postal_code')['has_claim'].mean().sort_values(ascending=False)\n",
    "        print(\"\\nTop 5 Postal Codes by Claim Frequency:\")\n",
    "        print(zip_freq.head(5))\n",
    "        print(\"\\nBottom 5 Postal Codes by Claim Frequency:\")\n",
    "        print(zip_freq.tail(5))\n",
    "        print(f\"Business Recommendation: The analysis indicates significant variation in claim frequency by postal code. Specific postal codes show notably higher or lower claim rates, which could be leveraged to refine geographical rating factors in premium calculations. Further granular analysis of high-frequency postal codes is recommended.\")\n",
    "    else:\n",
    "        print(\"Decision: Fail to Reject the Null Hypothesis (H₀).\")\n",
    "        print(\"Interpretation: There is no statistically significant difference in claim frequency across postal codes.\")\n",
    "else:\n",
    "    print(\"Not enough valid postal codes or sufficient data to perform Chi-squared test for Claim Frequency.\")\n",
    "\n",
    "\n",
    "# --- Claim Severity by Postal Code (ANOVA Test) ---\n",
    "print(\"\\nClaim Severity by Postal Code:\")\n",
    "# Filter for claims only for severity analysis\n",
    "postal_code_groups_severity = [df_claims_only['total_claims'][df_claims_only['postal_code'] == z] for z in df_claims_only['postal_code'].unique()]\n",
    "\n",
    "# Filter out groups with insufficient data (e.g., less than 2 observations for ANOVA)\n",
    "postal_code_groups_severity = [group for group in postal_code_groups_severity if len(group) > 1]\n",
    "\n",
    "if len(postal_code_groups_severity) > 1: # Ensure there's more than one group to compare\n",
    "    f_stat_zip_severity, p_value_zip_severity = f_oneway(*postal_code_groups_severity)\n",
    "    print(f\"\\nANOVA test for Claim Severity (Postal Code):\")\n",
    "    print(f\"F-statistic: {f_stat_zip_severity:.2f}, P-value: {p_value_zip_severity:.4f}\")\n",
    "\n",
    "    if p_value_zip_severity < 0.05:\n",
    "        print(\"Decision: Reject the Null Hypothesis (H₀).\")\n",
    "        print(\"Interpretation: There is a statistically significant difference in claim severity across postal codes.\")\n",
    "        # Business Recommendation for severity\n",
    "        zip_severity = df_claims_only.groupby('postal_code')['total_claims'].mean().sort_values(ascending=False)\n",
    "        print(\"\\nTop 5 Postal Codes by Claim Severity:\")\n",
    "        print(zip_severity.head(5))\n",
    "        print(\"\\nBottom 5 Postal Codes by Claim Severity:\")\n",
    "        print(zip_severity.tail(5))\n",
    "        print(f\"Business Recommendation: Claim severity varies significantly by postal code. Certain areas are associated with higher average claim costs, which could necessitate higher excesses or tailored product offerings in those regions to maintain profitability.\")\n",
    "    else:\n",
    "        print(\"Decision: Fail to Reject the Null Hypothesis (H₀).\")\n",
    "        print(\"Interpretation: There is no statistically significant difference in claim severity across postal codes.\")\n",
    "else:\n",
    "    print(\"Not enough unique postal codes with sufficient claims to perform ANOVA for Claim Severity.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "144c3843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hypothesis 3: Margin differences between zip codes (postal codes) ---\n",
      "\n",
      "Margin by Postal Code:\n",
      "\n",
      "ANOVA test for Margin (Postal Code):\n",
      "F-statistic: 0.89, P-value: 0.9911\n",
      "Decision: Fail to Reject the Null Hypothesis (H₀).\n",
      "Interpretation: There is no statistically significant difference in average margin across postal codes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Hypothesis 3: Margin differences between zip codes (postal codes) ---\n",
    "print(\"\\n--- Hypothesis 3: Margin differences between zip codes (postal codes) ---\")\n",
    "print(\"\\nMargin by Postal Code:\")\n",
    "# Group postal codes for ANOVA on margin\n",
    "# Filter out groups with insufficient data (e.g., less than 2 observations for ANOVA)\n",
    "postal_code_groups_margin = [df_processed['margin'][df_processed['postal_code'] == z] for z in df_processed['postal_code'].unique()]\n",
    "postal_code_groups_margin = [group for group in postal_code_groups_margin if len(group) > 1]\n",
    "\n",
    "if len(postal_code_groups_margin) > 1: # Ensure there's more than one group to compare\n",
    "    f_stat_zip_margin, p_value_zip_margin = f_oneway(*postal_code_groups_margin)\n",
    "    print(f\"\\nANOVA test for Margin (Postal Code):\")\n",
    "    print(f\"F-statistic: {f_stat_zip_margin:.2f}, P-value: {p_value_zip_margin:.4f}\")\n",
    "\n",
    "    if p_value_zip_margin < 0.05:\n",
    "        print(\"Decision: Reject the Null Hypothesis (H₀).\")\n",
    "        print(\"Interpretation: There is a statistically significant difference in average margin across postal codes.\")\n",
    "        zip_margin = df_processed.groupby('postal_code')['margin'].mean().sort_values(ascending=False)\n",
    "        print(\"\\nTop 5 Postal Codes by Average Margin:\")\n",
    "        print(zip_margin.head(5))\n",
    "        print(\"\\nBottom 5 Postal Codes by Average Margin:\")\n",
    "        print(zip_margin.tail(5))\n",
    "        print(f\"Business Recommendation: Significant variations in average margin by postal code indicate that pricing strategies could be further optimized at a granular geographic level. Areas with lower margins might require premium adjustments or closer review of associated risks/costs.\")\n",
    "    else:\n",
    "        print(\"Decision: Fail to Reject the Null Hypothesis (H₀).\")\n",
    "        print(\"Interpretation: There is no statistically significant difference in average margin across postal codes.\")\n",
    "else:\n",
    "    print(\"Not enough unique postal codes with sufficient data to perform ANOVA for Margin.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ffc4b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hypothesis 4: Risk differences between Women and Men ---\n",
      "\n",
      "Claim Frequency by Gender:\n",
      "has_claim      0   1\n",
      "gender              \n",
      "Female      6741  14\n",
      "Male       42723  94\n",
      "\n",
      "Chi-squared test for Claim Frequency (Gender):\n",
      "Chi2 Stat: 0.00, P-value: 0.9515\n",
      "Decision: Fail to Reject the Null Hypothesis (H₀).\n",
      "Interpretation: There is no statistically significant difference in claim frequency between genders.\n",
      "\n",
      "Claim Severity by Gender:\n",
      "\n",
      "T-test for Claim Severity (Gender - Welch's):\n",
      "T-statistic: -0.58, P-value: 0.5680\n",
      "Decision: Fail to Reject the Null Hypothesis (H₀).\n",
      "Interpretation: There is no statistically significant difference in claim severity between genders.\n",
      "\n",
      "Margin by Gender:\n",
      "\n",
      "T-test for Margin (Gender - Welch's):\n",
      "T-statistic: -0.25, P-value: 0.8015\n",
      "Decision: Fail to Reject the Null Hypothesis (H₀).\n",
      "Interpretation: There is no statistically significant difference in average margin between genders.\n"
     ]
    }
   ],
   "source": [
    "# --- Hypothesis 4: Risk differences between Women and Men ---\n",
    "print(\"\\n--- Hypothesis 4: Risk differences between Women and Men ---\")\n",
    "\n",
    "# Ensure 'gender' column is cleaned (e.g., 'Not specified' handled and filled with 'Unknown').\n",
    "# Filter to only 'Male' and 'Female' for comparison.\n",
    "df_gender_filtered = df_processed[df_processed['gender'].isin(['Male', 'Female'])].copy()\n",
    "\n",
    "if df_gender_filtered.empty:\n",
    "    print(\"Not enough 'Male' or 'Female' gender data to perform analysis for Hypothesis 4.\")\n",
    "else:\n",
    "    # --- Claim Frequency by Gender (Chi-squared Test) ---\n",
    "    print(\"\\nClaim Frequency by Gender:\")\n",
    "    contingency_table_gender_freq = pd.crosstab(df_gender_filtered['gender'], df_gender_filtered['has_claim'])\n",
    "    print(contingency_table_gender_freq)\n",
    "\n",
    "    # Ensure enough data for Chi-squared test (at least 2x2 table and not all zero counts)\n",
    "    if contingency_table_gender_freq.shape[0] > 1 and contingency_table_gender_freq.shape[1] > 1 and contingency_table_gender_freq.min().min() > 0:\n",
    "        chi2_gender_freq, p_value_gender_freq, _, _ = chi2_contingency(contingency_table_gender_freq)\n",
    "        print(f\"\\nChi-squared test for Claim Frequency (Gender):\")\n",
    "        print(f\"Chi2 Stat: {chi2_gender_freq:.2f}, P-value: {p_value_gender_freq:.4f}\")\n",
    "\n",
    "        if p_value_gender_freq < 0.05:\n",
    "            print(\"Decision: Reject the Null Hypothesis (H₀).\")\n",
    "            print(\"Interpretation: There is a statistically significant difference in claim frequency between genders.\")\n",
    "            gender_freq = df_gender_filtered.groupby('gender')['has_claim'].mean().sort_values(ascending=False)\n",
    "            print(\"\\nClaim Frequency by Gender (proportion of policies with claims):\")\n",
    "            print(gender_freq)\n",
    "            print(f\"Business Recommendation: Gender appears to be a significant factor in claim frequency. Policies for {gender_freq.index[0]} show a higher likelihood of claims, warranting gender-based premium adjustments.\")\n",
    "        else:\n",
    "            print(\"Decision: Fail to Reject the Null Hypothesis (H₀).\")\n",
    "            print(\"Interpretation: There is no statistically significant difference in claim frequency between genders.\")\n",
    "    else:\n",
    "        print(\"Not enough gender categories or observations for Chi-squared test on Claim Frequency.\")\n",
    "\n",
    "\n",
    "    # --- Claim Severity by Gender (T-test) ---\n",
    "    print(\"\\nClaim Severity by Gender:\")\n",
    "    # Filter for claims only and valid genders\n",
    "    df_claims_only_gender = df_claims_only[df_claims_only['gender'].isin(['Male', 'Female'])].copy()\n",
    "\n",
    "    male_claims = df_claims_only_gender[df_claims_only_gender['gender'] == 'Male']['total_claims']\n",
    "    female_claims = df_claims_only_gender[df_claims_only_gender['gender'] == 'Female']['total_claims']\n",
    "\n",
    "    if len(male_claims) > 1 and len(female_claims) > 1: # Ensure enough data for T-test\n",
    "        # Using Welch's t-test (equal_var=False) as it's more robust to unequal variances and sample sizes\n",
    "        t_stat_gender_severity, p_value_gender_severity = ttest_ind(male_claims, female_claims, equal_var=False)\n",
    "        print(f\"\\nT-test for Claim Severity (Gender - Welch's):\")\n",
    "        print(f\"T-statistic: {t_stat_gender_severity:.2f}, P-value: {p_value_gender_severity:.4f}\")\n",
    "\n",
    "        if p_value_gender_severity < 0.05:\n",
    "            print(\"Decision: Reject the Null Hypothesis (H₀).\")\n",
    "            print(\"Interpretation: There is a statistically significant difference in claim severity between genders.\")\n",
    "            gender_severity = df_claims_only_gender.groupby('gender')['total_claims'].mean().sort_values(ascending=False)\n",
    "            print(\"\\nClaim Severity by Gender (average claim amount for policies with claims):\")\n",
    "            print(gender_severity)\n",
    "            print(f\"Business Recommendation: When claims occur, the average claim amount differs significantly by gender. Policies for {gender_severity.index[0]} show higher severity, suggesting a need for gender-specific considerations in payout estimations or deductible offerings.\")\n",
    "        else:\n",
    "            print(\"Decision: Fail to Reject the Null Hypothesis (H₀).\")\n",
    "            print(\"Interpretation: There is no statistically significant difference in claim severity between genders.\")\n",
    "    else:\n",
    "        print(\"Not enough 'Male' or 'Female' policies with claims to perform T-test for Claim Severity.\")\n",
    "\n",
    "\n",
    "    # --- Margin by Gender (T-test) ---\n",
    "    print(\"\\nMargin by Gender:\")\n",
    "    # Use the df_gender_filtered which contains all policies with 'Male'/'Female' gender\n",
    "    male_margin = df_gender_filtered[df_gender_filtered['gender'] == 'Male']['margin']\n",
    "    female_margin = df_gender_filtered[df_gender_filtered['gender'] == 'Female']['margin']\n",
    "\n",
    "    if len(male_margin) > 1 and len(female_margin) > 1: # Ensure enough data for T-test\n",
    "        # Using Welch's t-test (equal_var=False)\n",
    "        t_stat_gender_margin, p_value_gender_margin = ttest_ind(male_margin, female_margin, equal_var=False)\n",
    "        print(f\"\\nT-test for Margin (Gender - Welch's):\")\n",
    "        print(f\"T-statistic: {t_stat_gender_margin:.2f}, P-value: {p_value_gender_margin:.4f}\")\n",
    "\n",
    "        if p_value_gender_margin < 0.05:\n",
    "            print(\"Decision: Reject the Null Hypothesis (H₀).\")\n",
    "            print(\"Interpretation: There is a statistically significant difference in average margin between genders.\")\n",
    "            gender_margin = df_gender_filtered.groupby('gender')['margin'].mean().sort_values(ascending=False)\n",
    "            print(\"\\nAverage Margin by Gender:\")\n",
    "            print(gender_margin)\n",
    "            print(f\"Business Recommendation: The average margin significantly differs between genders. Policies for {gender_margin.index[0]} generate higher average margins, which could influence targeted marketing or product development strategies based on profitability by gender segment.\")\n",
    "        else:\n",
    "            print(\"Decision: Fail to Reject the Null Hypothesis (H₀).\")\n",
    "            print(\"Interpretation: There is no statistically significant difference in average margin between genders.\")\n",
    "    else:\n",
    "        print(\"Not enough 'Male' or 'Female' policies with margin data to perform T-test for Margin.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
